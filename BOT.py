import asyncio
import os
import aiohttp
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message
from aiogram.filters import Command
import logging




# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
load_dotenv()

# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

logging.basicConfig(level=logging.INFO)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å—ë –∑–∞–≥—Ä—É–∂–µ–Ω–æ
if not BOT_TOKEN or not OPENROUTER_API_KEY:
    raise ValueError("‚ùå –ü—Ä–æ–≤–µ—Ä—å .env —Ñ–∞–π–ª! –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç BOT_TOKEN –∏–ª–∏ OPENROUTER_API_KEY.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ OpenRouter
BASE_URL = "https://openrouter.ai/api/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "Content-Type": "application/json",
    "HTTP-Referer": "https://yourdomain.com",  # –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å
    "X-Title": "TelegramLLMBot"
}

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—â–µ–Ω–∏—è —Å LLM
async def ask_llm(user_message):
    payload = {
        "model": "openai/gpt-4o",  # ‚úÖ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        "messages": [
            {"role": "user", "content": user_message}
        ]
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(BASE_URL, headers=HEADERS, json=payload) as response:
            data = await response.json()

            if response.status == 200 and "choices" in data:
                return data["choices"][0]["message"]["content"]
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ LLM:\nStatus: {response.status}\n{data}"
            
async def ask_llm(user_message):
    payload = {
        "model": "openai/gpt-4o",
        "messages": [
            {"role": "user", "content": user_message}
        ],
        "max_tokens": 1000  # ‚úÖ –£–∫–∞–∂–µ–º —Ä–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä 1000
    }

    async with aiohttp.ClientSession() as session:
        async with session.post(BASE_URL, headers=HEADERS, json=payload) as response:
            data = await response.json()

            if response.status == 200 and "choices" in data:
                return data["choices"][0]["message"]["content"]
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ LLM:\nStatus: {response.status}\n{data}"

        

# –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# /start
@dp.message(Command("start"))
async def start_handler(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø AI-–±–æ—Ç. –ù–∞–ø–∏—à–∏ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –∏ —è —Å–ø—Ä–æ—à—É —É LLM üí¨")

# /help
@dp.message(Command("help"))
async def help_handler(message: Message):
    await message.answer("–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç ‚Äî –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å —á–µ—Ä–µ–∑ OpenRouter GPT-4o.")

# –û–±—ã—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@dp.message(F.text)
async def message_handler(message: Message):
    user_input = message.text
    reply = await ask_llm(user_input)
    await message.answer(reply)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
